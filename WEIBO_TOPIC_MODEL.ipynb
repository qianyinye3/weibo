{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic model of Weibo Hot Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateRange(start, end, step=1, format=\"%Y/%m/%d\"):\n",
    "    strptime, strftime = datetime.datetime.strptime, datetime.datetime.strftime\n",
    "    days = (strptime(end, format) - strptime(start, format)).days\n",
    "    return [strftime(strptime(start, format) + datetime.timedelta(i), format) for i in range(0, days, step)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " if __name__ == '__main__':\n",
    "    dates = dateRange(\"2017/05/09\", \"2019/10/29\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将迭代的日期放入URL中，并逐个爬取网站，存入到dict中。\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "Keyword = []\n",
    "URL = []\n",
    "Count = []\n",
    "SearchCount = []\n",
    "Rank = []\n",
    "Date = []\n",
    "for i in dates:\n",
    "    re = requests.get('http://www.enlightent.com/research/top/getWeiboHotSearchDayAggs.do?date='+i)\n",
    "    re.encoding = 'utf-8'    \n",
    "    text = re.text\n",
    "    jsonobj = json.loads(text)\n",
    "    #print(jsonobj)\n",
    "\n",
    "    for item in jsonobj:\n",
    "        keyword = item['keyword']\n",
    "        Keyword.append(keyword)\n",
    "        url = item['url']\n",
    "        URL.append(url)\n",
    "\n",
    "        count = item['count']\n",
    "        Count.append(count)\n",
    "\n",
    "        searchCount = item['searchCount']\n",
    "        SearchCount.append(searchCount)\n",
    "\n",
    "        rank = item['rank']\n",
    "        Rank.append(rank)\n",
    "\n",
    "        Date.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将所有内容存入到csv文件中\n",
    "import csv\n",
    "datapage1 = {\n",
    "    'Date': Date,\n",
    "    'Keyword':Keyword,\n",
    "    'URL':URL,\n",
    "    'Count': Count,\n",
    "    'SearchCount':SearchCount,\n",
    "    'Rank': Rank,\n",
    "}\n",
    "weibo = pd.DataFrame.from_dict(datapage1, orient ='index').transpose()\n",
    "#print(weibo.info())\n",
    "weibo.to_csv('weibo_rank_2019_10_29.csv',index = False, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_clean(date):   \n",
    "    #date = line[2].replace(\"/\",\"-\")\n",
    "    date = date.split(\"/\")\n",
    "    if len(date[-2]) == 1:\n",
    "        date[-2] = \"0\"+ date[1]\n",
    "    if len(date[-1]) == 1:\n",
    "        date[-1] = \"0\" + date[2]\n",
    "    new_date = date[0]+\"-\"+date[1]+\"-\"+date[2]    \n",
    "    return   new_date  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('weibo_rank_2019_10_29.csv','r',encoding='utf-8')\n",
    "next(f)\n",
    "Year = []\n",
    "Month = []\n",
    "Date = []\n",
    "Title = []\n",
    "SearchCount = []\n",
    "Highest_Rank = []\n",
    "for line in f:\n",
    "    line = line.strip().split(\",\")\n",
    "    year = line[0]\n",
    "    month = line[1]\n",
    "    date = date_clean(line[2])   \n",
    "    title = line[3]\n",
    "    searchCount = line[5]\n",
    "    rank = line[4]\n",
    "\n",
    "    Year.append(year)\n",
    "    Month.append(month)\n",
    "    Date.append(date)\n",
    "    Title.append(title)\n",
    "    SearchCount.append(searchCount)\n",
    "    Highest_Rank.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>SeachCount</th>\n",
       "      <th>Highest_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215238</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>中国军团的军运时间</td>\n",
       "      <td>106604</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215239</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>冬令时</td>\n",
       "      <td>101231</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215240</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>宝蓝的莫甘娜</td>\n",
       "      <td>91356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215241</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>八一男排夺冠</td>\n",
       "      <td>89280</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215242</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>FPX先下一城</td>\n",
       "      <td>86423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215243</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>你听到过最奇葩的呼噜声</td>\n",
       "      <td>83952</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215244</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>惊蛰</td>\n",
       "      <td>74999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215245</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>主持人大赛</td>\n",
       "      <td>61331</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215246</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>刘迦街舞</td>\n",
       "      <td>45981</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215247</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>S9八强赛</td>\n",
       "      <td>27360</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year Month        Date        Title SeachCount Highest_Rank\n",
       "215238  2019    10  2019-10-27    中国军团的军运时间     106604            3\n",
       "215239  2019    10  2019-10-27          冬令时     101231            3\n",
       "215240  2019    10  2019-10-27       宝蓝的莫甘娜      91356            1\n",
       "215241  2019    10  2019-10-27       八一男排夺冠      89280            5\n",
       "215242  2019    10  2019-10-27      FPX先下一城      86423            1\n",
       "215243  2019    10  2019-10-27  你听到过最奇葩的呼噜声      83952           27\n",
       "215244  2019    10  2019-10-27           惊蛰      74999            2\n",
       "215245  2019    10  2019-10-27        主持人大赛      61331           33\n",
       "215246  2019    10  2019-10-27         刘迦街舞      45981           27\n",
       "215247  2019    10  2019-10-27        S9八强赛      27360            5"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Year':Year,\n",
    "    'Month':Month,\n",
    "    'Date':Date,\n",
    "    'Title':Title,\n",
    "    'SeachCount':SearchCount,\n",
    "    'Highest_Rank':Highest_Rank})\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True) # reset the index according to the number of the new data frame.\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference:\n",
    "stop words：\n",
    "    百度停用词表|\n",
    "    |哈工大停用词表\n",
    "    |四川大学机器智能实验试停用词库\n",
    "    |中文停用词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath,'r',encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "def cut(Title):\n",
    "    Title_cut = jieba.cut(Title)\n",
    "    stopwords = stopwordslist(\"STOPWORDS.txt\")\n",
    "    New_Title_cut = []\n",
    "    for word in Title_cut:\n",
    "        if word not in stopwords:\n",
    "            New_Title_cut.append(word)\n",
    "    New_Title_cut = str(New_Title_cut).replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\" \").replace(\"'\",\"\")\n",
    "    return New_Title_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>SeachCount</th>\n",
       "      <th>Highest_Rank</th>\n",
       "      <th>cutted_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175051</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>公交车司机的工位</td>\n",
       "      <td>97541</td>\n",
       "      <td>4</td>\n",
       "      <td>公交车  司机  工位</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175052</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>和平精英今日公测</td>\n",
       "      <td>87891</td>\n",
       "      <td>1</td>\n",
       "      <td>和平  精英  今日  公测</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175053</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>特朗普制裁伊朗钢铁业和矿业</td>\n",
       "      <td>85176</td>\n",
       "      <td>2</td>\n",
       "      <td>特朗普  制裁  伊朗  钢铁业  矿业</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175054</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>上海又一知名私募失联</td>\n",
       "      <td>28599</td>\n",
       "      <td>1</td>\n",
       "      <td>上海  知名  私募  失联</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175055</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>关税</td>\n",
       "      <td>26802</td>\n",
       "      <td>1</td>\n",
       "      <td>关税</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175056</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>盖茨妻子谈男女家务不平等</td>\n",
       "      <td>14926</td>\n",
       "      <td>16</td>\n",
       "      <td>盖茨  妻子  谈  男女  家务  平等</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175057</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>费莱尼绝杀</td>\n",
       "      <td>14614</td>\n",
       "      <td>10</td>\n",
       "      <td>费  莱尼  绝杀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175058</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>科学家用AI控制猴子大脑</td>\n",
       "      <td>7866</td>\n",
       "      <td>1</td>\n",
       "      <td>科学家  AI  控制  猴子  大脑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175059</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>韩国整形趋势女爱豆</td>\n",
       "      <td>6272</td>\n",
       "      <td>1</td>\n",
       "      <td>韩国  整形  趋势  女爱豆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175060</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>俄航副驾驶为救人重回起火客机</td>\n",
       "      <td>6253</td>\n",
       "      <td>1</td>\n",
       "      <td>俄航  副驾驶  救人  重回  起火  客机</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year Month        Date           Title SeachCount Highest_Rank  \\\n",
       "175051  2019     5  2019-05-09        公交车司机的工位      97541            4   \n",
       "175052  2019     5  2019-05-09        和平精英今日公测      87891            1   \n",
       "175053  2019     5  2019-05-09   特朗普制裁伊朗钢铁业和矿业      85176            2   \n",
       "175054  2019     5  2019-05-09      上海又一知名私募失联      28599            1   \n",
       "175055  2019     5  2019-05-09              关税      26802            1   \n",
       "175056  2019     5  2019-05-09    盖茨妻子谈男女家务不平等      14926           16   \n",
       "175057  2019     5  2019-05-09           费莱尼绝杀      14614           10   \n",
       "175058  2019     5  2019-05-09    科学家用AI控制猴子大脑       7866            1   \n",
       "175059  2019     5  2019-05-09       韩国整形趋势女爱豆       6272            1   \n",
       "175060  2019     5  2019-05-09  俄航副驾驶为救人重回起火客机       6253            1   \n",
       "\n",
       "                   cutted_title  \n",
       "175051              公交车  司机  工位  \n",
       "175052           和平  精英  今日  公测  \n",
       "175053     特朗普  制裁  伊朗  钢铁业  矿业  \n",
       "175054           上海  知名  私募  失联  \n",
       "175055                       关税  \n",
       "175056    盖茨  妻子  谈  男女  家务  平等  \n",
       "175057                费  莱尼  绝杀  \n",
       "175058      科学家  AI  控制  猴子  大脑  \n",
       "175059          韩国  整形  趋势  女爱豆  \n",
       "175060  俄航  副驾驶  救人  重回  起火  客机  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cutted_title'] = df['Title'].apply(cut)\n",
    "# one new column was generated\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://www.programcreek.com/python/example/83254/sklearn.feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic(start, end, num_topics, num_keywords):  # the function in outer layer\n",
    "    def periodize(start,end):                             # the function in inner layer\n",
    "        in_point=df[df['Date']==start].index.tolist()[0] # find the first index of small date\n",
    "        out_point=df[df['Date']==end].index.tolist()[-1]   # find the last index of big date\n",
    "        return df['cutted_title'][in_point:out_point]\n",
    "    # ↓ vectorizer is a local function, which could vectorize the text\n",
    "    vectorizer = CountVectorizer(max_features=3000,stop_words='english',min_df=0.001,max_df = 0.5)\n",
    "    tf = vectorizer.fit_transform(periodize(start,end)) # apply the vectorize function to the text\n",
    "    feature_names=vectorizer.get_feature_names() # features are numbers, while feature_names are names\n",
    "    # ↓ lda is a local function, which could select the topic\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, max_iter=100,random_state=0,\n",
    "                                    learning_method='online',learning_offset=50.).fit(tf)\n",
    "                                        # apply the vectorized text (i.e. tf) to lda↑    \n",
    "    for index, topic in enumerate(lda.components_): # topic is the number of features\n",
    "        Month = start.split(\"-\")[0]+ \"年\"+ start.split(\"-\")[1]+\"月\"\n",
    "        print(Month,'#%d:' % (index+1),\n",
    "              ' '.join([feature_names[i] for i in topic.argsort()[:-num_keywords - 1:-1]]),'\\n')\n",
    "# argsort() is a function which can generate a new index ↑\n",
    "# based on the existing list according to the size of the value of the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年01月 #1: 2018 喜欢 角色 扮演 2017 新年 杨幂 万元 转给 路费 \n",
      "\n",
      "2018年01月 #2: 跨年 新年 2017 吴昕 恋爱 李宇春 伦敦 升旗仪式 特朗普 体面 \n",
      "\n",
      "2018年01月 #3: 中国 年度 窦靖童 前任 巨星 演技 朴树 tt 苍井空 冻得 \n",
      "\n",
      "2018年01月 #4: 李易峰 烟花 gai 元旦 千玺 回应 加价 手术 患者 18000 \n",
      "\n",
      "2018年01月 #5: 假唱 陈伟霆 照片 日本 男子 成年 歌谣 祭典 追光 普京 \n",
      "\n",
      "2018年01月 #1: 2017 司机 美食 元旦 小伙 城市 法国 动车 降落 访华 \n",
      "\n",
      "2018年01月 #2: 回应 死亡 伊朗 示威 普京 10 后背 主题 按摩 餐厅 \n",
      "\n",
      "2018年01月 #3: 钱包 房企 彩绘 税改 百亿 政策 套房 羊肉 销售 高校学生 \n",
      "\n",
      "2018年01月 #4: 新年 攻略 比特 2018 烟花 丈夫 演技 城市 企鹅 一只 \n",
      "\n",
      "2018年01月 #5: 分钟 地铁 幸福 世界 小朋友 国旗 天安门 哨位 目标 模拟 \n",
      "\n",
      "2018年01月 #1: 新年 收购 写成 67 献词 擒拿 豆腐 证券报 检讨书 火腿 \n",
      "\n",
      "2018年01月 #2: 退役 巴尔德斯 中国 瑞士 猪肉 产品 马拉喀什 出口 摩洛哥 最高人民法院 \n",
      "\n",
      "2018年01月 #3: 春运 王思聪 预报地图 火车票 堆雪人 将进酒 全国 医药 按摩 归宿 \n",
      "\n",
      "2018年01月 #4: 世界各地 烟花 找人斗舞 轻易 跨年 魔方 豆沙 冰块 小丸子 草莓酱 \n",
      "\n",
      "2018年01月 #5: 小时 精髓 经济学 黄毅 攻略 公交 昏迷 人民 世界各地 苹果 \n",
      "\n",
      "2018年01月 #1: 跨年 走红 冬日 白菜 台历 神曲 纸屑 乐天 这组 洗脑 \n",
      "\n",
      "2018年01月 #2: 老师 女友 男子 朗诵 驾弃 古诗文 逃跑 走红 江苏 地震 \n",
      "\n",
      "2018年01月 #3: 2018 雪乡 比特 投家 币大涨 泰国 宰客 遭殃 采访 买入 \n",
      "\n",
      "2018年01月 #4: 小哥 国外 穆雷 超火 因伤 退出 尊巴 现场表演 健身 六方会谈 \n",
      "\n",
      "2018年01月 #5: 下雪 暴雪 预警 分钟 车祸 2017 消防官兵 这件 酷似 路由器 \n",
      "\n",
      "2018年01月 #1: 裸训 鹰爸 南京 中国 孩子 13 美国 118 球员 电信 \n",
      "\n",
      "2018年01月 #2: 小寒 pgone 老公 林心如 运势 顾家 肉沫 十号 豆腐 歌词 \n",
      "\n",
      "2018年01月 #3: 流浪 2018 叙利亚 俄驻 冒雪 空军基地 炮击 车轮 退出 茅台 \n",
      "\n",
      "2018年01月 #4: 降雪 影响 列车 另一半 地震 豆腐 辞职 流芳 冰窟窿 不想 \n",
      "\n",
      "2018年01月 #5: 30 游戏 回归 2019 权力 锁眼 住户 有来无回 乐队 布衣 \n",
      "\n",
      "2018年01月 #1: 母亲 20 专业 回归 10 踩油门 街道办 幸福 喷出 车尾 \n",
      "\n",
      "2018年01月 #2: 病逝 说话 pgone 新高 美国 初中生 3d 假肢 打印 贾乃亮 \n",
      "\n",
      "2018年01月 #3: 回应 16 嫌犯 贾乃亮 妈妈 公交站 枪杀 老人 联手 不到 \n",
      "\n",
      "2018年01月 #4: 重庆 公交 吊车 地震 天籁 落水 之战 妻子 浪漫 张杰 \n",
      "\n",
      "2018年01月 #5: 男子 小伙 诞生 凌晨 大熊猫 库蒂 17 老爸 双双 健身 \n",
      "\n",
      "2018年01月 #1: 世界 最强 萤火虫 晚上 嫁接 基因 植物 连凯 微博爆 流量 \n",
      "\n",
      "2018年01月 #2: 少女 火场 联盟 全市 大学生 地铁 倡议 辛芷蕾 魔卡 喝酒 \n",
      "\n",
      "2018年01月 #3: 孩子 周一围 制作 王者 立新 前任 男子 中小学生 天门山 肝癌 \n",
      "\n",
      "2018年01月 #4: 贾乃亮 交警 高校 暴雪 李小璐 安徽 国安 离家出走 温泉 ai \n",
      "\n",
      "2018年01月 #5: 女朋友 翟天临 螃蟹 库里 45 万块 餐馆老板 19 讨要 美国 \n",
      "\n",
      "2018年01月 #1: 中国 培训 三点 放学 小学生 朋友圈 钟汉良 天宇 下雪 争夺 \n",
      "\n",
      "2018年01月 #2: 宿舍 奖状 学霸 金球奖 官员 儿科 吴彦祖 红花 翟天临 不肯 \n",
      "\n",
      "2018年01月 #3: 网红 全国 儿子 去世 胡杏儿 王源 地铁 正面 国宝 流感 \n",
      "\n",
      "2018年01月 #4: 游记 寻梦 金球奖 纽约 生日 静静的 过个 成都 美国 杨清柠 \n",
      "\n",
      "2018年01月 #5: 回应 90 世界 同一个 老妈 曼联 恒大 五月天 周杰伦 总统 \n",
      "\n",
      "2018年01月 #1: 组织 开会 传销 其境 红糖 ktv 随便 发糕 声临 孔明灯 \n",
      "\n",
      "2018年01月 #2: 冬季 骑士 快递 亿件 流感 去年 收费 多地 我国 400 \n",
      "\n",
      "2018年01月 #3: 苹果 徒手 会谈 高铁 通道 诉讼 26 双节棍 降速 周杰伦 \n",
      "\n",
      "2018年01月 #4: 金球奖 声明 成都 蔬果 工作岗位 小妙 广告牌 环卫工 25 剥离 \n",
      "\n",
      "2018年01月 #5: 儿子 黄晓明 助攻 庆祝 金色 妆容 洛瑞 滑梯 汤普森 学生 \n",
      "\n",
      "2018年01月 #1: 冰花 男孩 王凯 泰国 人形 不苦 立牌 总理 中国空军 宣传片 \n",
      "\n",
      "2018年01月 #2: 总统 广州 房贷利率 英特尔 法国 中文 加剧 病疫情 南非 李斯特 \n",
      "\n",
      "2018年01月 #3: 世界地图 蛋壳 三轮车 平均 孕妇 男子 报警 传唤 派出所 扫把 \n",
      "\n",
      "2018年01月 #4: 欣赏 宠物 天气 选修课 简笔画 一根 编发 皮筋 超萌 香港 \n",
      "\n",
      "2018年01月 #5: 爱尔兰 拐杖 扫路 风暴 小伙 踢球 练就 40 最强 大脑 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-01-01','2018-01-01',5,10)\n",
    "extract_topic('2018-01-02','2018-01-02',5,10)\n",
    "extract_topic('2018-01-03','2018-01-03',5,10)\n",
    "extract_topic('2018-01-04','2018-01-04',5,10)\n",
    "extract_topic('2018-01-05','2018-01-05',5,10)\n",
    "extract_topic('2018-01-06','2018-01-06',5,10)\n",
    "extract_topic('2018-01-07','2018-01-07',5,10)\n",
    "extract_topic('2018-01-08','2018-01-08',5,10)\n",
    "extract_topic('2018-01-09','2018-01-09',5,10)\n",
    "extract_topic('2018-01-10','2018-01-10',5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年01月 #1: 中国 回应 2018 恋爱 歌手 10 手机 2017 儿子 女儿 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-01-01','2018-01-27',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年02月 #1: 春晚 中国 春节 过年 女儿 妈妈 春运 地震 回家 10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-02-03','2018-02-27',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年03月 #1: 中国 男孩 回应 女儿 偶遇 女生 女孩 妈妈 老人 周杰伦 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-03-01','2018-03-31',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年04月 #1: 中国 回应 手机 鹿晗 女儿 徐坤 北京 周杰伦 偶遇 千玺 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-04-01','2018-04-30',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年05月 #1: 妈妈 中国 回应 温暖 徐坤 鹿晗 詹姆斯 演唱会 儿子 戛纳 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-05-01','2018-05-31',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年06月 #1: 世界杯 高考 回应 中国 101 德国 球迷 毕业 阿根廷 直播 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-06-01','2018-06-30',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年07月 #1: 回应 世界杯 中国 扶摇 朱一龙 疫苗 法国 演唱会 直播 白宇 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-07-01','2018-07-31',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年08月 #1: 回应 滴滴 中国 攻略 延禧 香蜜 沉沉 亚运会 如霜 七夕 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-08-01','2018-08-31',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年09月 #1: 回应 中国 台风 中秋 开学 滴滴 道歉 如懿传 山竹 iphone \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-09-01','2018-09-30',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年10月 #1: 回应 中国 坠江 唐嫣 rng 李咏 婚礼 国庆 游客 结婚 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-10-01','2018-10-31',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年11月 #1: 回应 王思聪 粉丝 中国 11 蒋劲夫 道歉 ig 快递 双十 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-11-01','2018-11-30',1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年12月 #1: 回应 2018 中国 否认 考研 海王 结婚 圣诞 男孩 粉丝 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_topic('2018-12-01','2018-12-31',1,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
